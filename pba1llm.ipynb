{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado el conjunto de artistas y grupos proporcionados, parece que hay una mezcla diverso en términos de géneros musicales. Sin embargo, puedo clasificar algunos de estos elementos dentro del género clásico o música ligera tradicional basándome en la presencia de piezas conocidas y el estilo de sus miembros más destacados:\n",
      "\n",
      "\n",
      "1. **Miracle Musical** - Aunque principalmente es una banda pop contemporánea, algunas de sus canciones pueden contener elementos de música clásica debido al uso de instrumentos como cuerdas y percusiones en su producción musical.\n",
      "\n",
      "\n",
      "2. **Elis Regina** - Una cantante brasileña conocida por interpretar obras clásicas del repertorio latinoamericano, como el bolero \"Perfidia\".\n",
      "enas claves son:\n",
      "\n",
      "- Elis Regina es famosa por sus versiones de canciones clásicas y populares, lo que la incluye en este grupo.\n",
      "\n",
      "- Shaggy, conocido principalmente por su música reggae, no se ajusta claramente al género clásico pero podría ser considerado una voz distintiva dentro del panorama musical contemporáneo.\n",
      "\n",
      "- Coco & Clair Clair es un dúo de música académica y clásica, lo que los sitúa firmemente en este grupo.\n",
      "\n",
      "- BADBADNOTGOOD, A$AP Mob, entre otros, son grupos o artistas de hip hop y no se ajustan al género clásico musical; sin embargo, podrían incorporar elementos del jazz o la música contemporánea con influencias clásicas en sus composiciones.\n",
      "\n",
      "- Billie Holiday es una cantante conocida por su interpretación de canciones jazzísticas que a menudo incluyen arreglos y estilos cercanos al género clásico, lo cual la hace relevante para este grupo.\n",
      "\n",
      "- Michael Bublé es un tenor pop conocido también por sus interpretaciones vocales de canciones clásicas y está muy asociado con el género vocal clásico-popular.\n",
      "\n",
      "- Otras figuras como Lou Reed, Ray Charles, o The Zombies son más asociados al rock, soul y pop, respectivamente, aunque su trabajo puede tener ciertos elementos que remiten a influencias musicales más amplias que incluyen el clásico.\n",
      "\n",
      "\n",
      "En conclusión, los grupos de género clásico en la lista provista serían principalmente Coco & Clair Clair (dúo de música académica y clásica) y Michael Bublé por su influencia en las interpretaciones vocales de canciones clásicas. Los otros artistas mencionados pueden tener conexiones más indirectas o no tienen una asignación directa al género clásico, pero sus trabajos a veces se mezclan con elementos del mismo repertorio clásico.\n",
      "Kings of Convenience es un dúo musical formado por el noruego Erlend Øye y la australiana Annbjørg Lien. Aunque no están directamente relacionados con todos los nombres mencionados anteriormente, pueden tener cierta afinidad en términos de música pop y alternativa.\n",
      "\n",
      "Dicho esto, aquí te presentaré información relevante sobre Kings of Convenience que puede relacionarse indirectamente con algunos artistas o canciones del listado proporcionado:\n",
      "\n",
      "1. Shaggy: No hay una directa relación entre King of Convenience y el artista Shaggy; sin embargo, ambos representan diferentes géneros musicales en sus respectivos trabajos.\n",
      "2. Coco & Clair Clair: Aunque no tienen conexión directa, ambas bandas exploraron temáticas alternativas y experimentales en su música.\n",
      "3. Billie Holiday: No hay una relación directa entre Kings of Convenience y la cantante Billie Holiday; sin embargo, ambos artistas han tenido influencia significativa en el mundo de la música.\n",
      "4. Erik Satie: Aunque no hay conexión directa, Erik Satie fue un compositor francés conocido por su estilo experimental e inconformista.\n",
      "5. Aliyah's Interlude: No hay una relación directa entre Kings of Convenience y esta pista de música hip hop; sin embargo, ambos artistas han experimentado con diferentes estilos musicales en sus carreras.\n",
      "6. Baco Exu do Blues: Aunque no hay una conexión directa, este dúo brasileño ha explorado temáticas únicas y distintivas en su música, similar a cómo Kings of Convenience lo hace.\n",
      "7. Muna: Aunque no tienen relación directa, ambas bandas han experimentado con el género alternativo y la música pop indie.\n",
      "8. Ludmilla: No hay una relación directa entre los artistas mencionados en la lista y Kings of Convenience; sin embargo, Ludmilla es una cantante brasileña que ha tenido éxito en diferentes géneros musicales.\n",
      "9. Magic!: Aunque no tienen conexión directa, esta banda canadiense también se ha desempeñado en el género alternativo y pop indie.\n",
      "1e. GFRIEND: Aunque no hay una relación directa entre la banda coreana GFRIEND y Kings of Convenience, ambas han trabajado dentro del mundo de la música pop.\n",
      "\n",
      "Si deseas información específica relacionada con los otros artistas o canciones mencionados en el listado, por favor proporcióneme más detalles.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "# Simulando la carga de datos del archivo JSON\n",
    "def load_music_data():\n",
    "    with open('data/music_data.json', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "music_data = load_music_data()\n",
    "\n",
    "def embed_query(query):\n",
    "    # Simulación de un proceso de creación de embeddings basado en extracción de palabras clave\n",
    "    keywords = query.lower().split()\n",
    "    return keywords\n",
    "\n",
    "def retrieve_data(keywords, data):\n",
    "    # Simulación de recuperación de datos más sofisticada\n",
    "    relevant_artists = set()\n",
    "    for artist in data:\n",
    "        artist_data = f\"{artist['name'].lower()} {artist['bio'].lower()}\"\n",
    "        for album in artist['albums']:\n",
    "            album_data = f\"{album['name'].lower()} {' '.join(album['genres']).lower()}\"\n",
    "            if any(keyword in album_data for keyword in keywords):\n",
    "                relevant_artists.add(artist['name'])\n",
    "    return ', '.join(relevant_artists) if relevant_artists else \"No se encontró información relevante.\"\n",
    "\n",
    "def filter_by_genre(data, genre):\n",
    "    # Función existente para filtrar artistas por género\n",
    "    filtered_artists = []\n",
    "    for artist in data:\n",
    "        for album in artist['albums']:\n",
    "            if genre.lower() in [g.lower() for g in album['genres']]:\n",
    "                filtered_artists.append(artist['name'])\n",
    "                break\n",
    "    return filtered_artists\n",
    "\n",
    "def postprocess_response(response):\n",
    "    # Limpieza de la respuesta\n",
    "    return response\n",
    "\n",
    "def generate_response(user_query):\n",
    "    # Generación de respuesta completa utilizando LLM\n",
    "    keywords = embed_query(user_query)\n",
    "    relevant_data = retrieve_data(keywords, music_data)\n",
    "    prompt = f\"Usuario: {user_query}\\nInformación relevante: {relevant_data}\\nRespuesta:\"\n",
    "    response = ollama.chat(model='phi3', messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    return postprocess_response(response['message']['content'])\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(generate_response(\"dame grupos de genero classical\"))\n",
    "print(generate_response(\"información sobre Kings of convenience\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado tu solicitud de grupos que se ajusten al género clásico o con influencias del mismo, aquí hay una lista de artistas y bandas que tienen elementos o han tenido relaciones históricamente con el género clásico, aunque la mayoría no son puramente clasistas:\n",
      "\n",
      "\n",
      "1. **Erik Satie** - Compositor francés conocido por su música minimalista con influencias del neoclasicismo.\n",
      "\n",
      "2. **Cream** - Grupo británico de rock que incorporó elementos jazz en sus canciones, lo cual puede encontrarse en la tradición clásica.\n",
      "\n",
      "3. **The Prodigy** - Banda de música electrónica con reminiscencias al rock y el pop moderno, pero su sonido a menudo recuerda a los arreglos orquestales y compositores del siglo XX.\n",
      "\n",
      "4. **Mild High Club** - Una banda que mezcla elementos de electro-pop clásico y jazz con ritmos atemporales.\n",
      "\n",
      "5. **A$AP Mob** - Aunque principalmente es conocido por su enfoque contemporáneo, el grupo ha sido influenciado por música afroamericana tradicional, la cual comparte raíces históricas con algunas formas de música clásica.\n",
      "\n",
      "6. **Ozuna** - Un artista de reguetón que, aunque es moderno y no directamente clasista, puede explorar estructuras rítmicas similares a las encontradas en la música barroca o romántica.\n",
      "\n",
      "\n",
      "Es importante tener en cuenta que muchas bandas y artistas mencionados anteriormente son reconocidos por su estilo contemporáneo, pero algunas de sus influencias musicales pueden ofrecer conexiones históricas o estilísticas al mundo del género clásico.\n",
      "\n",
      "Artistas del género classical: Erik Satie\n",
      "Kings of Convenience es un dúo musical noruego compuesto por miembros Eirik Høeg y Majan Odnes. Aunque no son directamente asociados con los artistas mencionados como Ray Charles o The Zombies, su música tiene una atmósfera cálida y familiar que podría resonar con aficionados de géneros diversos incluidos aquí en la lista proporcionada.\n",
      "\n",
      "En cuanto a las influencias del dúo Kings of Convenience, sus composiciones tienen un tono nostálgico e íntimo, con elementos de pop y folk rock que pueden evocar reminiscencias a artistas como Cream o The Prodigy por su enfoque melódico. Aunque no hay una conexión directa con los nombres dados, la versatilidad musical del dúo permite un amplio espectro de gustos y podría atraer a aquellos que disfrutan del pop clásico, como Dean Martin, o del indie alternativo en artistas como Lou Reed.\n",
      "\n",
      "Si buscas más información sobre Kings of Convenience y su música, te recomendamos escuchar sus álbumes \"Life on Earth\" (2014) y \"For Now, Forever\" (2018), que muestran la evolución de su estilo y son un testimonio al vínculo emocional con el público.\n",
      "\n",
      "Si tu interés se inclina en artistas o grupos más relacionados con las listas proporcionadas, Kings of Convenience podría no ser el grupo perfecto para ti. Sin embargo, si buscas una experiencia musical que te lleve a recuerdos y emociones nostálgicos, sus obras son dignas de exploración.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "# Simulando la carga de datos del archivo JSON\n",
    "def load_music_data():\n",
    "    with open('data/music_data.json', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "music_data = load_music_data()\n",
    "\n",
    "def embed_query(query):\n",
    "    # Simulación de un proceso de creación de embeddings basado en extracción de palabras clave\n",
    "    keywords = query.lower().split()\n",
    "    return keywords\n",
    "\n",
    "def retrieve_data(keywords, data):\n",
    "    # Simulación de recuperación de datos más sofisticada\n",
    "    relevant_artists = set()\n",
    "    for artist in data:\n",
    "        artist_data = f\"{artist['name'].lower()} {artist['bio'].lower()}\"\n",
    "        for album in artist['albums']:\n",
    "            album_data = f\"{album['name'].lower()} {' '.join(album['genres']).lower()}\"\n",
    "            if any(keyword in album_data for keyword in keywords):\n",
    "                relevant_artists.add(artist['name'])\n",
    "    \n",
    "    if relevant_artists:\n",
    "        return f\"Artistas relevantes: {', '.join(relevant_artists)}\"\n",
    "    else:\n",
    "        return \"No se encontró información relevante.\"\n",
    "\n",
    "def filter_by_genre(data, genre):\n",
    "    # Función existente para filtrar artistas por género\n",
    "    filtered_artists = []\n",
    "    for artist in data:\n",
    "        for album in artist['albums']:\n",
    "            if genre.lower() in [g.lower() for g in album['genres']]:\n",
    "                filtered_artists.append(artist['name'])\n",
    "                break\n",
    "    return filtered_artists\n",
    "\n",
    "def postprocess_response(response, user_query):\n",
    "    # Posprocesamiento de la respuesta\n",
    "    if \"genero\" in user_query.lower():\n",
    "        genre = user_query.lower().split(\"genero\")[-1].strip()\n",
    "        filtered_artists = filter_by_genre(music_data, genre)\n",
    "        if filtered_artists:\n",
    "            response += f\"\\n\\nArtistas del género {genre}: {', '.join(filtered_artists)}\"\n",
    "        else:\n",
    "            response += f\"\\n\\nNo se encontraron artistas del género {genre}.\"\n",
    "    return response\n",
    "\n",
    "def generate_response(user_query):\n",
    "    # Generación de respuesta completa utilizando LLM\n",
    "    keywords = embed_query(user_query)\n",
    "    relevant_data = retrieve_data(keywords, music_data)\n",
    "    prompt = f\"Usuario: {user_query}\\nInformación relevante: {relevant_data}\\nRespuesta:\"\n",
    "    response = ollama.chat(model='phi3', messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    return postprocess_response(response['message']['content'], user_query)\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(generate_response(\"dame grupos de genero classical\"))\n",
    "print(generate_response(\"información sobre Kings of convenience\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo determinar tu personalidad basada en tu autodefinición.\n",
      "\n",
      "En la historia de los Grammy Awards, ninguno de los artistas mencionados ha ganado múltiples premios Grammy en varias categorías. Sin embargo, el artista que más veces ha sido nominado es Bono Vox de U2 con 160 nominaciones hasta diciembre de 2ayer año. Pero cabe destacar que Ray Charles fue uno de los artistas más premiados con un total de 38 premios Grammy en su carrera.\n",
      "\n",
      "Pero si hablamos del galardón específico de \"Grammy Award for Album of the Year\" (Mejor Álbum) y la cantidad de victorias, el ganador con mayor número es Alicia Keys, que ha recibido 9 premios en esta categoría.\n",
      "\n",
      "Es importante mencionar que los premios Grammy se otorgan generalmente por una o dos categorías cada año; por lo tanto, la cantidad de victorias a nivel individual puede variar considerablemente.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "# Simulando la carga de datos del archivo JSON\n",
    "def load_music_data():\n",
    "    with open('data/music_data.json', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "music_data = load_music_data()\n",
    "\n",
    "# Cargando el mapeo de géneros a personalidades\n",
    "def load_genre_personality_mapping():\n",
    "    with open('data/genres_personalities.json', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "genre_personality_mapping = load_genre_personality_mapping()\n",
    "\n",
    "def identify_personality(user_genres):\n",
    "    personality_scores = {}\n",
    "    for genre in user_genres:\n",
    "        if genre.lower() in genre_personality_mapping:\n",
    "            for trait in genre_personality_mapping[genre.lower()]:\n",
    "                personality_scores[trait] = personality_scores.get(trait, 0) + 1\n",
    "    \n",
    "    if personality_scores:\n",
    "        dominant_personality = max(personality_scores, key=personality_scores.get)\n",
    "        return dominant_personality\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def embed_query(query):\n",
    "    # Simulación de un proceso de creación de embeddings basado en extracción de palabras clave\n",
    "    keywords = query.lower().split()\n",
    "    return keywords\n",
    "\n",
    "def retrieve_data(keywords, data):\n",
    "    # Simulación de recuperación de datos más sofisticada\n",
    "    relevant_artists = set()\n",
    "    for artist in data:\n",
    "        artist_data = f\"{artist['name'].lower()} {artist['bio'].lower()}\"\n",
    "        for album in artist['albums']:\n",
    "            album_data = f\"{album['name'].lower()} {' '.join(album['genres']).lower()}\"\n",
    "            if any(keyword in album_data for keyword in keywords):\n",
    "                relevant_artists.add(artist['name'])\n",
    "    \n",
    "    if relevant_artists:\n",
    "        return f\"Artistas relevantes: {', '.join(relevant_artists)}\"\n",
    "    else:\n",
    "        return \"No se encontró información relevante.\"\n",
    "\n",
    "def postprocess_response(response, user_query, personality):\n",
    "    # Posprocesamiento de la respuesta\n",
    "    if personality:\n",
    "        response = f\"Basado en tu autodefinición, tu personalidad parece ser: {personality}.\\n\\n{response}\"\n",
    "    else:\n",
    "        response = f\"No se pudo determinar tu personalidad basada en tu autodefinición.\\n\\n{response}\"\n",
    "    return response\n",
    "\n",
    "def generate_response(user_query, user_genres):\n",
    "    # Identificar la personalidad del usuario basada en los géneros proporcionados\n",
    "    personality = identify_personality(user_genres)\n",
    "    \n",
    "    # Generación de respuesta completa utilizando LLM\n",
    "    keywords = embed_query(user_query)\n",
    "    relevant_data = retrieve_data(keywords, music_data)\n",
    "    prompt = f\"Usuario: {user_query}\\nInformación relevante: {relevant_data}\\nRespuesta:\"\n",
    "    response = ollama.chat(model='phi3', messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    return postprocess_response(response['message']['content'], user_query, personality)\n",
    "\n",
    "# Ejemplo de uso\n",
    "user_personality = input(\"¿Cómo te defines a ti mismo? (introvertido, extrovertido, creativo, aventurero): \")\n",
    "user_genres = [genre.strip() for genre in input(\"Ingresa algunos de tus géneros musicales favoritos (separados por coma): \").split(\",\")]\n",
    "user_query = input(\"Ingresa tu consulta sobre música: \")\n",
    "print(generate_response(user_query, user_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado tu interés en el género rock y considerando los artistas relevantes mencionados, aquí te presento algunos grupos de géneros rock que podrinas disfrutar:\n",
      "\n",
      "1. Psychedelic Rock: Cream (con Eric Clapton y Jack Bruce), Pink Floyd\n",
      "2. Blues-Rock: The Zombies, Big Mama Thornton, Baco Exu do Blues\n",
      "3. Pop-Rock: Michael Bublé, Glee Cast\n",
      "4. Alternative/Indie Rock: Lou Reed, Good Charlotte, A$AP Mob, Ozuna (bajo la conciencia de que Ozuna es un rapero que ha explorado el rock en algunas de sus producciones)\n",
      "5. Punk Rock: The Prodigy, Green Day\n",
      "6. Soft Rock/Pop-Rock: Michael Bublé, Jason Mraz\n",
      "7. Garage Rock Revival: Guided by Voices, The Black Keys\n",
      "8. New Wave/Synthpop: Depeche Mode, Duran Duran\n",
      "9. Latin Rock: Saba, Olly Alexander (Years & Years)\n",
      "10. Folk-Rock: Elli Sa'Edera, Cream\n",
      "\n",
      "Es importante tener en cuenta que algunos artistas mencionados pueden pertenecer a diferentes géneros musicales o son conocidos por explorar múltiples estilos, como Lou Reed y Ozuna. Esto hace que la asignación de un género sea más flexible e interesante para aquellos con gustos amplios.\n",
      "Kings of Convenience es un dúo de música folk procedente de Noruega que forman parte del movimiento indie-folk contemporáneo y ha sido aclamado por su hermosa interpretación melódica y profundidad lírica. No aparecen en la lista de artistas relevantes proporcionada, pero sí hay algunos elementos comunes con varios músicos mencionados.\n",
      "\n",
      "Aunque no están directamente relacionados con los artistas nombrados anteriormente (Ray Charles, Erik Satie, Tom Petty, Baco Exu do Blues, Lou Reed, Dean Martin, GFRIEND, Cream, The Zombies, The La's, Michael Cera, Olly Alexander de Years & Years, Saba, Chris Stapleton, LeeHi, Danny Brown, Coolio, Saweetie, Shaggy, Adventure Time, The Prodigy, Mild High Club, Meduza, Muna, Coco & Clair Clair, Ludmilla, Good Charlotte, Billie Holiday, Kordhell, Frou Frou, The Ink Spots y Aliyah's Interlude), algunos aspectos de la música de Kings of Convenience podren resonar con las características mencionadas (extroversión, creatividad, introversión e aventura).\n",
      "\n",
      "El dúo está formado por el vocalista y guitarrista Jørgen Linga y la cantante y bajista Marion Rung. Han sido reconocidos por su manera única de experimentar con la música folk tradicional, mezclando estilos clásicos como bluegrass y country con elementos contemporáneos para crear una propuesta musical original e innovadora.\n",
      "\n",
      "En cuanto a personalidades asociadas a ellos, no se han identificado en el listado proporcionado. Sin embargo, la música de Kings of Convenience ha sido celebrada por su capacidad para evocar emociones y permitir una experiencia musical introspectiva que puede aliviar tanto la extroversión como la introversión.\n",
      "\n",
      "A continuación encontrarás algunos de sus trabajos más destacados:\n",
      "\n",
      "- \"In the Waiting Line\" (2004)\n",
      "- \"Simple As This\" (2005)\n",
      "- \"From Yr to Ma Sky\" (2 Vol. 1 y 2, 2007)\n",
      "- \"Ratterbull\" (2011)\n",
      "- \"Sleepless Remixes\" (2013)\n",
      "- \"Between You and Me\" (2015)\n",
      "- \"Kings of Convenience\" (2018)\n",
      "\n",
      "Si estás interesado en explorar más sobre la música de Kings of Convenience, te recomendamos escuchar sus álbumes y buscar entrevistas o artículos que puedan proporcionarte información adicional sobre su estilo musical e influencia.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "# Carga de datos de música y personalidades\n",
    "def load_music_data():\n",
    "    with open('data/music_data.json', encoding='utf-8') as file:\n",
    "        music_data = json.load(file)\n",
    "    with open('data/genres_personalities.json', encoding='utf-8') as file:\n",
    "        personalities_data = json.load(file)\n",
    "    return music_data, personalities_data\n",
    "\n",
    "music_data, personalities_data = load_music_data()\n",
    "\n",
    "def embed_query(query):\n",
    "    return query.lower().split()\n",
    "\n",
    "def retrieve_data(keywords, data, personalities):\n",
    "    relevant_artists = set()\n",
    "    artist_personalities = []\n",
    "    for artist in data:\n",
    "        for album in artist['albums']:\n",
    "            album_data = f\"{album['name'].lower()} {' '.join(album['genres']).lower()}\"\n",
    "            for keyword in keywords:\n",
    "                if keyword in album_data:\n",
    "                    relevant_artists.add(artist['name'])\n",
    "                    # Añadir personalidades basadas en géneros del álbum\n",
    "                    for genre in album['genres']:\n",
    "                        if genre.lower() in personalities:\n",
    "                            artist_personalities.extend(personalities[genre.lower()])\n",
    "\n",
    "    response = f\"Artistas relevantes: {', '.join(relevant_artists)}\"\n",
    "    if artist_personalities:\n",
    "        unique_personalities = set(artist_personalities)\n",
    "        response += f\". Personalidades asociadas: {', '.join(unique_personalities)}\"\n",
    "    return response if relevant_artists else \"No se encontró información relevante.\"\n",
    "\n",
    "def generate_response(user_query):\n",
    "    keywords = embed_query(user_query)\n",
    "    relevant_data = retrieve_data(keywords, music_data, personalities_data)\n",
    "    prompt = f\"Usuario: {user_query}\\nInformación relevante: {relevant_data}\\nRespuesta:\"\n",
    "    response = ollama.chat(model='phi3', messages=[{'role': 'user', 'content': prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(generate_response(\"dame grupos de genero rock\"))\n",
    "print(generate_response(\"información sobre Kings of Convenience\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como persona con una personalidad creativa, te encantarían géneros musicales que reflejen tu espíritu innovador y expresivo. Aquí tienes algunas recomendaciones para fomentar su vibra creativa:\n",
      "\n",
      "1. Indie Rock: Un género experimental donde la originalidad y la búsqueda de nuevos sonidos tienen un lugar central. Algunos artistas como Arctic Monkeys, The Strokes o Tame Impala podrían encantarte.\n",
      "\n",
      "2. Synth-pop / Electropop: Estos géneros mezclan elementos electrónicos con la melodía pegajosa y pop clásico. Artistas como Daft Punk, Pet Shop Boys o The Chemical Brothers pueden ser de gran interés para ti.\n",
      "\n",
      "3. Trap-Soul / Hip-Hop Alternativo: Una combinación del soul emocional con la energía impulsora del hip-hop, que te invita a explorar nuevos matices y perspectivas creativas. Algunos artistas interesantes son Kendrick Lamar, J.I.D o Lil Uzi Vert.\n",
      "\n",
      "4. Experimental / Avant-Garde: Estos géneros desafían los límites de la música convencional al introducir elementos inesperados y una sensibilidad única. Puedes explorar artistas como Björk, Radiohead o Sigur Rós para inspirarte.\n",
      "\n",
      "5. Lo-Fi / Chillwave: Una fusión entre los ritmos lentos de la música electrónica con un toque nostálgico y melancólico. Esto te puede llevar a descubrir artistas como Washed Out, Toro Y Moja o Beach Fossils.\n",
      "\n",
      "Recuerda que tu personalidad creativa no necesariamente limita tus opciones musicales; estas recomendaciones solo sirven para guiarte hacia algunas posibilidades interesantes en el mundo de la música. ¡Disfruta y explora!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "# Carga de datos de música y personalidades\n",
    "def load_music_data():\n",
    "    with open('data/music_data.json', encoding='utf-8') as file:\n",
    "        music_data = json.load(file)\n",
    "    with open('data/genres_personalities.json', encoding='utf-8') as file:\n",
    "        personalities_data = json.load(file)\n",
    "    return music_data, personalities_data\n",
    "\n",
    "music_data, personalities_data = load_music_data()\n",
    "\n",
    "def get_genres_by_personality(personality, personalities_data):\n",
    "    genres = []\n",
    "    for genre, personalities in personalities_data.items():\n",
    "        if personality.lower() in [p.lower() for p in personalities]:\n",
    "            genres.append(genre)\n",
    "    return genres\n",
    "\n",
    "def retrieve_data(keywords, data, genres):\n",
    "    relevant_artists = set()\n",
    "    for artist in data:\n",
    "        artist_data = f\"{artist['name'].lower()} {artist['bio'].lower()}\"\n",
    "        for album in artist['albums']:\n",
    "            album_data = f\"{album['name'].lower()} {' '.join(album['genres']).lower()}\"\n",
    "            if any(keyword in artist_data or keyword in album_data for keyword in keywords):\n",
    "                if any(genre.lower() in [g.lower() for g in album['genres']] for genre in genres):\n",
    "                    relevant_artists.add(artist['name'])\n",
    "    \n",
    "    if relevant_artists:\n",
    "        response = f\"Artistas relevantes para tu personalidad: {', '.join(relevant_artists)}.\"\n",
    "        return response\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_response(user_query, user_personality):\n",
    "    keywords = user_query.lower().split()\n",
    "    genres = get_genres_by_personality(user_personality, personalities_data)\n",
    "    relevant_data = retrieve_data(keywords, music_data, genres)\n",
    "    \n",
    "    if relevant_data:\n",
    "        prompt = f\"Usuario con personalidad {user_personality} busca: {user_query}\\nInformación relevante: {relevant_data}\\nRespuesta:\"\n",
    "        response = ollama.chat(model='phi3', messages=[{'role': 'user', 'content': prompt}])\n",
    "        return response['message']['content']\n",
    "    else:\n",
    "        prompt = f\"Usuario con personalidad {user_personality} busca recomendaciones de música. Géneros asociados a esta personalidad: {', '.join(genres)}.\\nRespuesta:\"\n",
    "        response = ollama.chat(model='phi3', messages=[{'role': 'user', 'content': prompt}])\n",
    "        return response['message']['content']\n",
    "\n",
    "# Ejemplo de uso\n",
    "user_personality = input(\"Ingresa tu personalidad (extrovertido, introvertido, creativo, aventurero): \")\n",
    "user_query = input(\"Ingresa tu consulta sobre música: \")\n",
    "print(generate_response(user_query, user_personality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (1.11.4)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
      "Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB 991.0 kB/s eta 0:00:25\n",
      "   ---------------------------------------- 0.1/24.0 MB 991.0 kB/s eta 0:00:25\n",
      "   ---------------------------------------- 0.2/24.0 MB 1.6 MB/s eta 0:00:16\n",
      "    --------------------------------------- 0.3/24.0 MB 2.0 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.5/24.0 MB 2.3 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.7/24.0 MB 2.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.1/24.0 MB 3.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.4/24.0 MB 3.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.6/24.0 MB 4.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.9/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.4/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.1/24.0 MB 5.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.2/24.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.5/24.0 MB 5.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.8/24.0 MB 5.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.2/24.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.7/24.0 MB 5.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.0/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.4/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.8/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.0/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.1/24.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.5/24.0 MB 5.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 6.9/24.0 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.3/24.0 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.5/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.7/24.0 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 7.9/24.0 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.3/24.0 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.5/24.0 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.9/24.0 MB 5.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.2/24.0 MB 5.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.5/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.5/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.1/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.3/24.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.6/24.0 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 10.9/24.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.4/24.0 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 11.7/24.0 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.2/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.4/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 12.8/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.0/24.0 MB 6.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.1/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.7/24.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.1/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.5/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.6/24.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.9/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.2/24.0 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.8/24.0 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.3/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.3/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 16.9/24.0 MB 6.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.4/24.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.9/24.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.0/24.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.3/24.0 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.6/24.0 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.2/24.0 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.0 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.1/24.0 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.3/24.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.8/24.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.1/24.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.4/24.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.1/24.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.5/24.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.7/24.0 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.4/24.0 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.8/24.0 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.2/61.2 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pinecone-client\n",
      "Version: 4.1.0\n",
      "Summary: Pinecone client and SDK\n",
      "Home-page: https://www.pinecone.io\n",
      "Author: Pinecone Systems, Inc.\n",
      "Author-email: support@pinecone.io\n",
      "License: Apache-2.0\n",
      "Location: c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages\n",
      "Requires: certifi, tqdm, typing-extensions, urllib3\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip show pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (4.1.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from pinecone-client) (2023.11.17)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from pinecone-client) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from pinecone-client) (4.8.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from pinecone-client) (1.26.18)\n",
      "Requirement already satisfied: colorama in c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (c:\\users\\antap\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decodificando el JSON de la respuesta para el texto: Who is Muse?\n",
      "Respuesta recibida: To generate an embedding for the given text \"Who is Muse?\", we'll use a pre-trained language model such as BERT (from the transformers library by Hugging Face), which can understand and process the semantics of natural language. The following demonstrates how to achieve this using Python:\n",
      "\n",
      "```python\n",
      "from transformers import BertTokenizer, TFBertModel\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "\n",
      "# Load pre-trained model tokenizer (vocabulary)\n",
      "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
      "\n",
      "# Encode the text into tokens and input IDs for BERT\n",
      "text = \"Who is Muse?\"\n",
      "encoded_input = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
      "\n",
      "# Load pre-trained BERT model\n",
      "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
      "\n",
      "# Get the embeddings from the last layer of the model (usually [CLS] token embedding is used for text classification tasks)\n",
      "with tf.device('/CPU:0' if 'cpu' in device_type else '/GPU:0'):  # Ensure TensorFlow operations are performed on CPU/GPU as appropriate\n",
      "    outputs = model(encoded_input['input_ids'])\n",
      "    embeddings = outputs[1][-1]  # The last layer output for the embedding representation\n",
      "\n",
      "# Convert tensors to numpy arrays\n",
      "embedding_vector = np.squeeze(embeddings)[0].numpy()\n",
      "\n",
      "print(\"Generated Embedding:\", embedding_vector)\n",
      "```\n",
      "\n",
      "Please note that this code assumes you have TensorFlow installed and properly set up, as well as the transformers library. The output `embedding_vector` will be a 768-dimensional vector representing the text \"Who is Muse?\" in an embedding space where semantically similar texts are closer together.\n",
      "Error procesando la consulta. Por favor, intenta nuevamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import ollama\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Configurar la clave de API de Pinecone\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"c602bc00-16d5-40ee-9bf2-02afd832212c\"\n",
    "\n",
    "# Inicializar el cliente de Pinecone\n",
    "pinecone = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "# Crear o conectar a un índice de Pinecone\n",
    "index_name = \"music-embeddings\"  # Asegúrate de que solo contiene caracteres en minúsculas y guiones\n",
    "dimension = 1536  # Dimensión de los embeddings generados por Phi3\n",
    "metric = \"cosine\"  # Métrica de similitud utilizada por Pinecone\n",
    "if index_name not in pinecone.list_indexes().names():\n",
    "    # Asegúrate de que la especificación de \"spec\" es correcta según la documentación actual de Pinecone\n",
    "    spec = {\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}}\n",
    "    pinecone.create_index(name=index_name, dimension=dimension, metric=metric, spec=spec)\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Carga de datos de música y personalidades\n",
    "def load_music_data():\n",
    "    with open('data/music_data.json', encoding='utf-8') as file:\n",
    "        music_data = json.load(file)\n",
    "    with open('data/genres_personalities.json', encoding='utf-8') as file:\n",
    "        personalities_data = json.load(file)\n",
    "    return music_data, personalities_data\n",
    "\n",
    "music_data, personalities_data = load_music_data()\n",
    "\n",
    "def get_genres_by_personality(personality, personalities_data):\n",
    "    genres = []\n",
    "    for genre, personalities in personalities_data.items():\n",
    "        if personality.lower() in [p.lower() for p in personalities]:\n",
    "            genres.append(genre)\n",
    "    return genres\n",
    "\n",
    "def embed_text(text):\n",
    "    response = ollama.chat(model='phi3', messages=[{'role': 'user', 'content': f'Generate an embedding for the following text: \"{text}\"'}])\n",
    "    embedding_str = response['message']['content'].strip()\n",
    "    try:\n",
    "        embedding = np.array(json.loads(embedding_str))\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decodificando el JSON de la respuesta para el texto: {text}\")\n",
    "        print(f\"Respuesta recibida: {embedding_str}\")\n",
    "        return None\n",
    "    return embedding\n",
    "\n",
    "def retrieve_data(query_embedding, genres):\n",
    "    results = index.query(query_embedding, top_k=10, include_metadata=True)\n",
    "    relevant_artists = []\n",
    "    for match in results['matches']:\n",
    "        artist_data = match['metadata']\n",
    "        if any(genre.lower() in [g.lower() for g in artist_data['genres']] for genre in genres):\n",
    "            relevant_artists.append((artist_data['name'], match['score']))\n",
    "    if relevant_artists:\n",
    "        relevant_artists.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_artists = [artist[0] for artist in relevant_artists[:5]]  # Obtiene los 5 artistas más relevantes\n",
    "        response = f\"Artistas relevantes para tu personalidad: {', '.join(top_artists)}.\"\n",
    "        return response\n",
    "    else:\n",
    "        return \"No se encontraron artistas relevantes.\"\n",
    "\n",
    "def generate_response(user_query, user_personality):\n",
    "    genres = get_genres_by_personality(user_personality, personalities_data)\n",
    "    query_embedding = embed_text(user_query)\n",
    "    if query_embedding is None:\n",
    "        return \"Error procesando la consulta. Por favor, intenta nuevamente.\"\n",
    "    relevant_data = retrieve_data(query_embedding, genres)\n",
    "    if relevant_data:\n",
    "        prompt = f\"Usuario con personalidad {user_personality} busca: {user_query}\\nInformación relevante: {relevant_data}\\nRespuesta:\"\n",
    "        response = ollama.chat(model='phi3', messages=[{'role': 'user', 'content': prompt}])\n",
    "        return response['message']['content']\n",
    "    else:\n",
    "        prompt = f\"Usuario con personalidad {user_personality} busca recomendaciones de música. Géneros asociados a esta personalidad: {', '.join(genres)}.\\nRespuesta:\"\n",
    "        response = ollama.chat(model='phi3', messages=[{'role': 'user', 'content': prompt}])\n",
    "        return response['message']['content']\n",
    "\n",
    "# Ejemplo de uso\n",
    "user_personality = input(\"Ingresa tu personalidad (extrovertido, introvertido, creativo, aventurero): \")\n",
    "user_query = input(\"Ingresa tu consulta sobre música: \")\n",
    "print(generate_response(user_query, user_personality))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Configuración inicial\u001b[39;00m\n\u001b[0;32m     10\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_pinecone_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPINECONE_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_index_name\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Función para generar embeddings con BERT\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pinecone\\deprecation_warnings.py:38\u001b[0m, in \u001b[0;36minit\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     11\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m    import os\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m        )\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     31\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124mPlease create an instance of the Pinecone class instead.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import ollama\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Configuración inicial\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"your_pinecone_api_key\"\n",
    "pinecone.init(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "index_name = \"your_index_name\"\n",
    "\n",
    "# Función para generar embeddings con BERT\n",
    "def generate_bert_embedding(text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    encoded_input = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "    outputs = model(encoded_input['input_ids'])\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].numpy()  # Tomamos el embedding del token CLS\n",
    "    return embeddings.flatten()\n",
    "\n",
    "# Función para buscar en Pinecone y generar respuesta con Ollama\n",
    "def generate_response(query):\n",
    "    query_embedding = generate_bert_embedding(query)\n",
    "    results = pinecone.query(index_name, query_embedding, top_k=5)\n",
    "    top_results = [result['metadata']['name'] for result in results]\n",
    "    \n",
    "    # Usar Ollama para generar respuesta contextual\n",
    "    prompt = f\"El usuario preguntó: {query}\\nLos mejores resultados son: {', '.join(top_results)}\"\n",
    "    response = ollama.chat(model='phi3', messages=[{'role': 'user', 'content': prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(generate_response(\"dame grupos de genero rock\"))\n",
    "print(generate_response(\"información sobre Kings of Convenience\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\antap\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_bert_embedding(text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    encoded_input = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "    outputs = model(encoded_input['input_ids'])\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token's embeddings\n",
    "    return embeddings.numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Crear una instancia de Pinecone\n",
    "pinecone_client = pinecone.Pinecone(api_key=\"c602bc00-16d5-40ee-9bf2-02afd832212c\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_index() missing 1 required positional argument: 'spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Verificar si el índice ya existe\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pinecone_client\u001b[38;5;241m.\u001b[39mlist_indexes()\u001b[38;5;241m.\u001b[39mnames():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Crear un nuevo índice si no existe\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mpinecone_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Conectar al índice\u001b[39;00m\n\u001b[0;32m     10\u001b[0m index \u001b[38;5;241m=\u001b[39m pinecone_client\u001b[38;5;241m.\u001b[39mIndex(name\u001b[38;5;241m=\u001b[39mindex_name)\n",
      "\u001b[1;31mTypeError\u001b[0m: create_index() missing 1 required positional argument: 'spec'"
     ]
    }
   ],
   "source": [
    "index_name = \"embeddings_index\"\n",
    "dimension = 768  # Asegúrate de que la dimensión coincida con la de tus embeddings\n",
    "\n",
    "# Verificar si el índice ya existe\n",
    "if index_name not in pinecone_client.list_indexes().names():\n",
    "    # Crear un nuevo índice si no existe\n",
    "    pinecone_client.create_index(name=index_name, dimension=dimension, metric=\"cosine\")\n",
    "\n",
    "# Conectar al índice\n",
    "index = pinecone_client.Index(name=index_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
